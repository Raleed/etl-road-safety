{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "707a681a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./database_functions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9140756f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "from typing import List, Optional\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.engine import Engine\n",
    "from sqlalchemy import text\n",
    "from psycopg2.extras import execute_values\n",
    "from sqlalchemy_utils import database_exists, create_database\n",
    "import logging\n",
    "import pandas as pd\n",
    "\n",
    "CLEAN_DIR = Path(\"../data/cleaned\")\n",
    "RAW_DIR = Path(\"../data/raw\")\n",
    "CLEAN_DIR.mkdir(parents=True, exist_ok=True)\n",
    "RAW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "ADMIN_DB_URL = \"postgresql+psycopg2://postgres:postgres2025%40@localhost:54785/postgres\"\n",
    "DB_NAME = \"db_accident\"\n",
    "DB_URL = ADMIN_DB_URL.rsplit(\"/\", 1)[0] + f\"/{DB_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fe2c8fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# DDL : bronze \n",
    "# ---------------------------\n",
    "script_bronze_dll = \"\"\"\n",
    "CREATE SCHEMA IF NOT EXISTS bronze;\n",
    "\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS bronze.caracteristiques_raw (\n",
    "  identifiant_de_l_accident TEXT,\n",
    "  date_et_heure TEXT,\n",
    "  jour TEXT,\n",
    "  mois TEXT,\n",
    "  annee TEXT,\n",
    "  heure_minute TEXT,\n",
    "  date TEXT,\n",
    "  year_georef TEXT,\n",
    "  lumiere TEXT,\n",
    "  code_postal TEXT,\n",
    "  code_insee TEXT,\n",
    "  departement TEXT,\n",
    "  commune TEXT,\n",
    "  code_commune TEXT,\n",
    "  code_officiel_commune TEXT,\n",
    "  nom_officiel_commune TEXT,\n",
    "  nom_officiel_commune_arrondissement_municipal TEXT,\n",
    "  code_officiel_departement TEXT,\n",
    "  nom_officiel_departement TEXT,\n",
    "  code_officiel_region TEXT,\n",
    "  nom_officiel_region TEXT,\n",
    "  code_officiel_epci TEXT,\n",
    "  nom_officiel_epci TEXT,\n",
    "  localisation TEXT,\n",
    "  intersection TEXT,\n",
    "  conditions_atmospheriques TEXT,\n",
    "  collision TEXT,\n",
    "  adresse TEXT,\n",
    "  gps TEXT,\n",
    "  latitude TEXT,\n",
    "  longitude TEXT,\n",
    "  coordonnees TEXT,\n",
    "  numero TEXT  \n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS bronze.lieux_raw (\n",
    "  identifiant_de_l_accident TEXT,\n",
    "  categorie_route TEXT,\n",
    "  voie TEXT,\n",
    "  v1 TEXT,\n",
    "  v2 TEXT,\n",
    "  circulation TEXT,\n",
    "  nombre_de_voies TEXT,\n",
    "  voie_reservee TEXT,\n",
    "  profil TEXT,\n",
    "  pr TEXT,\n",
    "  pr1 TEXT,\n",
    "  plan TEXT,\n",
    "  largeur_terre_plein_central TEXT,\n",
    "  largeur_de_la_chaussee TEXT,\n",
    "  surface TEXT,\n",
    "  infrastructure TEXT,\n",
    "  situation TEXT,\n",
    "  env1 TEXT\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS bronze.vehicules_raw (\n",
    "  identifiant_de_l_accident TEXT,\n",
    "  identifiant_vehicule TEXT,\n",
    "  sens TEXT,\n",
    "  categorie_vehicule TEXT,\n",
    "  obstacle_fixe_heurte TEXT,\n",
    "  obstacle_mobile_heurte TEXT,\n",
    "  point_de_choc TEXT,\n",
    "  manoeuvre TEXT,\n",
    "  nombre_d_occupants TEXT\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS bronze.usagers_raw (\n",
    "  identifiant_de_l_accident TEXT,\n",
    "  identifiant_vehicule TEXT,\n",
    "  place TEXT,\n",
    "  categorie_d_usager TEXT,\n",
    "  gravite TEXT,\n",
    "  sexe TEXT,\n",
    "  annee_de_naissance TEXT,\n",
    "  motif_trajet TEXT,\n",
    "  existence_equipement_de_securite TEXT,\n",
    "  utilisation_equipement_de_securite TEXT,\n",
    "  localisation_du_pieton TEXT,\n",
    "  action_pieton TEXT,\n",
    "  pieton_seul_ou_non TEXT\n",
    ");\n",
    "\n",
    "CREATE INDEX IF NOT EXISTS br_car_ident_idx ON bronze.caracteristiques_raw (identifiant_de_l_accident);\n",
    "CREATE INDEX IF NOT EXISTS br_lieux_ident_idx ON bronze.lieux_raw (identifiant_de_l_accident);\n",
    "CREATE INDEX IF NOT EXISTS br_veh_ident_idx ON bronze.vehicules_raw (identifiant_de_l_accident);\n",
    "CREATE INDEX IF NOT EXISTS br_usg_ident_idx ON bronze.usagers_raw (identifiant_de_l_accident);\n",
    "\n",
    "CREATE INDEX IF NOT EXISTS br_car_dep_idx ON bronze.caracteristiques_raw (departement);\n",
    "CREATE INDEX IF NOT EXISTS br_car_date_idx ON bronze.caracteristiques_raw (annee, mois);\n",
    "CREATE INDEX IF NOT EXISTS br_veh_catv_idx ON bronze.vehicules_raw (categorie_vehicule);\n",
    "CREATE INDEX IF NOT EXISTS br_usg_grav_idx ON bronze.usagers_raw (gravite);\n",
    "\"\"\"\n",
    "create_database_if_not_exists(ADMIN_DB_URL, DB_NAME)\n",
    "engine = get_engine(DB_URL)\n",
    "execute_script(engine, script_bronze_dll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "47e25499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_name = \"accidents_clean.csv\"\n",
    "# try:\n",
    "#     df_cleaned = pd.read_csv(CLEAN_DIR / csv_name,\n",
    "#                      sep=\";\", dtype=str, encoding=\"utf-8-sig\")\n",
    "# except UnicodeDecodeError:\n",
    "#     df_cleaned = pd.read_csv(CLEAN_DIR / csv_name,\n",
    "#                      sep=\";\", dtype=str, encoding=\"utf-8-sig\")\n",
    "\n",
    "# print(\"Colonnes détectées:\", list(df.columns)[:8], \"...\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ce travail dois etre fait apres l'importation des données brutes et stockéés\n",
    "# et generer les resultats sous forme de fichier accidents_clean.csv \n",
    "# comme ça on utilise directement le code commenterci dessus\n",
    "csv_name = \"accidents-corporels-de-la-circulation-millesime.csv\"\n",
    "try:\n",
    "    df = pd.read_csv(RAW_DIR / csv_name,\n",
    "                     sep=\";\", dtype=str, encoding=\"utf-8-sig\")\n",
    "except UnicodeDecodeError:\n",
    "    df = pd.read_csv(RAW_DIR / csv_name,\n",
    "                     sep=\";\", dtype=str, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"Colonnes détectées:\", list(df.columns)[:8], \"...\")\n",
    "\n",
    "\n",
    "def normalize_columns(df, inplace=False):\n",
    "    \"\"\"\n",
    "    Normalise les noms de colonnes d'un DataFrame en snake_case sans accents ni caractères spéciaux.\n",
    "    Règles :\n",
    "      - retire les accents\n",
    "      - met en minuscules\n",
    "      - remplace tout caractère non alphanumérique par un underscore\n",
    "      - réduit les underscores multiples en un seul\n",
    "      - supprime les underscores en début/fin\n",
    "      - si le nom commence par un chiffre, préfixe par 'c_'\n",
    "      - si le résultat est vide, remplace par 'unknown'\n",
    "      - garantit l'unicité des noms en ajoutant des suffixes _2, _3, ...\n",
    "    Arguments :\n",
    "      df : pandas.DataFrame\n",
    "      inplace : bool (False par défaut). Si True, renomme les colonnes sur place et retourne le même objet.\n",
    "    Retour :\n",
    "      pandas.DataFrame avec colonnes normalisées.\n",
    "    \"\"\"\n",
    "    import unicodedata\n",
    "    import re\n",
    "    import pandas as pd\n",
    "\n",
    "    if not inplace:\n",
    "        df = df.copy()\n",
    "\n",
    "    def _slug(name: object) -> str:\n",
    "        s = \"\" if name is None else str(name)\n",
    "        # Normaliser unicode et séparer les accents\n",
    "        s = unicodedata.normalize(\"NFKD\", s)\n",
    "        # Enlever les caractères de composition (accents)\n",
    "        s = \"\".join(ch for ch in s if not unicodedata.combining(ch))\n",
    "        s = s.lower()\n",
    "        # Remplacer tout caractère non alphanumérique par underscore\n",
    "        s = re.sub(r\"[^a-z0-9]+\", \"_\", s)\n",
    "        # Réduire underscores multiples et trim\n",
    "        s = re.sub(r\"_+\", \"_\", s).strip(\"_\")\n",
    "        # Préfixer si commence par chiffre\n",
    "        if re.match(r\"^[0-9]\", s):\n",
    "            s = \"c_\" + s\n",
    "        if s == \"\":\n",
    "            s = \"unknown\"\n",
    "        return s\n",
    "\n",
    "    # Appliquer la normalisation\n",
    "    orig_cols = list(df.columns)\n",
    "    normalized = [_slug(c) for c in orig_cols]\n",
    "\n",
    "    # Garantir l'unicité des noms\n",
    "    seen = {}\n",
    "    unique_cols = []\n",
    "    for name in normalized:\n",
    "        base = name\n",
    "        if name not in seen:\n",
    "            seen[name] = 1\n",
    "            unique_cols.append(name)\n",
    "        else:\n",
    "            seen[name] += 1\n",
    "            new_name = f\"{base}_{seen[name]}\"\n",
    "            # garantir que new_name lui-même n'existe pas déjà\n",
    "            while new_name in seen:\n",
    "                seen[base] += 1\n",
    "                new_name = f\"{base}_{seen[base]}\"\n",
    "            seen[new_name] = 1\n",
    "            unique_cols.append(new_name)\n",
    "\n",
    "    # Renommer le DataFrame\n",
    "    mapping = dict(zip(orig_cols, unique_cols))\n",
    "    df = df.rename(columns=mapping)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "808a699c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['identifiant_de_l_accident',\n",
       " 'date_et_heure',\n",
       " 'commune',\n",
       " 'annee',\n",
       " 'mois',\n",
       " 'jour',\n",
       " 'heure_minute',\n",
       " 'lumiere',\n",
       " 'localisation',\n",
       " 'intersection',\n",
       " 'conditions_atmospheriques',\n",
       " 'collision',\n",
       " 'departement',\n",
       " 'code_commune',\n",
       " 'code_insee',\n",
       " 'adresse',\n",
       " 'latitude',\n",
       " 'longitude',\n",
       " 'code_postal',\n",
       " 'numero',\n",
       " 'coordonnees',\n",
       " 'pr',\n",
       " 'surface',\n",
       " 'v1',\n",
       " 'circulation',\n",
       " 'voie_reservee',\n",
       " 'env1',\n",
       " 'voie',\n",
       " 'largeur_de_la_chaussee',\n",
       " 'v2',\n",
       " 'largeur_terre_plein_central',\n",
       " 'nombre_de_voies',\n",
       " 'categorie_route',\n",
       " 'pr1',\n",
       " 'plan',\n",
       " 'profil',\n",
       " 'infrastructure',\n",
       " 'situation',\n",
       " 'annee_de_naissance',\n",
       " 'sexe',\n",
       " 'action_pieton',\n",
       " 'gravite',\n",
       " 'existence_equipement_de_securite',\n",
       " 'utilisation_equipement_de_securite',\n",
       " 'localisation_du_pieton',\n",
       " 'identifiant_vehicule',\n",
       " 'place',\n",
       " 'categorie_d_usager',\n",
       " 'pieton_seul_ou_non',\n",
       " 'motif_trajet',\n",
       " 'point_de_choc',\n",
       " 'man_uvre',\n",
       " 'sens',\n",
       " 'obstacle_mobile_heurte',\n",
       " 'obstacle_fixe_heurte',\n",
       " 'categorie_vehicule',\n",
       " 'nombre_d_occupants',\n",
       " 'gps',\n",
       " 'date',\n",
       " 'year_georef',\n",
       " 'nom_officiel_commune',\n",
       " 'code_officiel_departement',\n",
       " 'nom_officiel_departement',\n",
       " 'code_officiel_epci',\n",
       " 'nom_officiel_epci',\n",
       " 'code_officiel_region',\n",
       " 'nom_officiel_region',\n",
       " 'nom_officiel_commune_arrondissement_municipal',\n",
       " 'code_officiel_commune']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned = normalize_columns(df, inplace=True)\n",
    "df_cleaned.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea14eda7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "475911"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_colonnes = [\n",
    "    \"identifiant_de_l_accident\",\n",
    "    \"date_et_heure\",\n",
    "    \"jour\",\n",
    "    \"mois\",\n",
    "    \"annee\",\n",
    "    \"heure_minute\",\n",
    "    \"date\",\n",
    "    \"year_georef\",\n",
    "    \"lumiere\",\n",
    "    \"code_postal\",\n",
    "    \"code_insee\",\n",
    "    \"departement\",\n",
    "    \"commune\",\n",
    "    \"code_commune\",\n",
    "    \"code_officiel_commune\",\n",
    "    \"nom_officiel_commune\",\n",
    "    \"nom_officiel_commune_arrondissement_municipal\",\n",
    "    \"code_officiel_departement\",\n",
    "    \"nom_officiel_departement\",\n",
    "    \"code_officiel_region\",\n",
    "    \"nom_officiel_region\",\n",
    "    \"code_officiel_epci\",\n",
    "    \"nom_officiel_epci\",\n",
    "    \"localisation\",\n",
    "    \"intersection\",\n",
    "    \"conditions_atmospheriques\",\n",
    "    \"collision\",\n",
    "    \"adresse\",\n",
    "    \"gps\",\n",
    "    \"latitude\",\n",
    "    \"longitude\",\n",
    "    \"coordonnees\",\n",
    "    \"numero\"\n",
    "]\n",
    "\n",
    "df_filtred_to_insert = df_cleaned[table_colonnes].copy()\n",
    "insert_df_to_table(engine, df_filtred_to_insert, \"bronze\", \"caracteristiques_raw\",\n",
    "                   table_columns=table_colonnes, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1a047ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "475911"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_colonnes = [\n",
    "    \"identifiant_de_l_accident\",\n",
    "    \"categorie_route\",\n",
    "    \"voie\",\n",
    "    \"v1\",\n",
    "    \"v2\",\n",
    "    \"circulation\",\n",
    "    \"nombre_de_voies\",\n",
    "    \"voie_reservee\",\n",
    "    \"profil\",\n",
    "    \"pr\",\n",
    "    \"pr1\",\n",
    "    \"plan\",\n",
    "    \"largeur_terre_plein_central\",\n",
    "    \"largeur_de_la_chaussee\",\n",
    "    \"surface\",\n",
    "    \"infrastructure\",\n",
    "    \"situation\",\n",
    "    \"env1\"\n",
    "]\n",
    "df_filtred_to_insert = df_cleaned[table_colonnes].copy()\n",
    "insert_df_to_table(engine, df_filtred_to_insert, \"bronze\", \"lieux_raw\",\n",
    "                   table_columns=table_colonnes, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "80da58aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "475911"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# changer le nom du colonne \n",
    "df_cleaned.rename(\n",
    "    columns={\n",
    "        'man_uvre': 'manoeuvre',\n",
    "    },\n",
    "    inplace=True\n",
    ")\n",
    "table_colonnes = [\n",
    "    \"identifiant_de_l_accident\",\n",
    "    \"identifiant_vehicule\",\n",
    "    \"sens\",\n",
    "    \"categorie_vehicule\",\n",
    "    \"obstacle_fixe_heurte\",\n",
    "    \"obstacle_mobile_heurte\",\n",
    "    \"point_de_choc\",\n",
    "    \"manoeuvre\",\n",
    "    \"nombre_d_occupants\"\n",
    "]\n",
    "\n",
    "df_filtred_to_insert = df_cleaned[table_colonnes].copy()\n",
    "insert_df_to_table(engine, df_filtred_to_insert, \"bronze\", \"vehicules_raw\",\n",
    "                   table_columns=table_colonnes, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fe16515c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "475911"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_colonnes = [\n",
    "    \"identifiant_de_l_accident\",\n",
    "    \"identifiant_vehicule\",\n",
    "    \"place\",\n",
    "    \"categorie_d_usager\",   \n",
    "    \"gravite\",\n",
    "    \"sexe\",\n",
    "    \"annee_de_naissance\",\n",
    "    \"motif_trajet\",                         \n",
    "    \"existence_equipement_de_securite\",\n",
    "    \"utilisation_equipement_de_securite\",  \n",
    "    \"localisation_du_pieton\",            \n",
    "    \"action_pieton\",                       \n",
    "    \"pieton_seul_ou_non\"\n",
    "]\n",
    "df_filtred_to_insert = df_cleaned[table_colonnes].copy()\n",
    "insert_df_to_table(engine, df_filtred_to_insert, \"bronze\", \"usagers_raw\",\n",
    "                   table_columns=table_colonnes, batch_size=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eee73f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Toutes les connexions à 'db_accident' ont été fermées (sauf la session actuelle).\n",
      "INFO:__main__:Engine SQLAlchemy libéré — plus aucune connexion active.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2225, 'postgres', 'db_accident', 'idle', 'COMMIT')\n",
      "(2225, 'postgres', 'db_accident', 'idle', 'COMMIT')\n"
     ]
    }
   ],
   "source": [
    "admin_engine = get_engine(ADMIN_DB_URL)\n",
    "show_open_connections(admin_engine, DB_NAME)\n",
    "close_all_connections(admin_engine, DB_NAME)\n",
    "show_open_connections(admin_engine, DB_NAME)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
