{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c53ae98f",
   "metadata": {},
   "source": [
    "# Bronze DDL ‚Äî PostgreSQL sur localhost\n",
    "\n",
    "Ce notebook :\n",
    "1. Charge la configuration depuis un fichier `.env` (ou variables d'environnement).\n",
    "2. V√©rifie l'existence de la base de donn√©es cible et la cr√©e si besoin (via un compte **superuser**).\n",
    "3. Ex√©cute **tous** les fichiers SQL situ√©s dans `../sql/bronze/*.sql` dans l'ordre alphab√©tique.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4089b0dd",
   "metadata": {},
   "source": [
    "## Pr√©requis\n",
    "\n",
    "- Python 3.10+\n",
    "- Paquets : `psycopg2-binary`, `SQLAlchemy`, `python-dotenv`\n",
    "- Un serveur PostgreSQL accessible\n",
    "- Cr√©ez un fichier `.env` √† la racine du projet (copiez `.env.example`) et renseignez les valeurs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897abd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation (√† ex√©cuter une seule fois dans votre venv)\n",
    "# !pip install psycopg2-binary SQLAlchemy python-dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f226306d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "dotenv_path = pathlib.Path(r\".env\")\n",
    "if dotenv_path.exists():\n",
    "    load_dotenv(dotenv_path)\n",
    "    print(\"‚úÖ .env charg√© :\", dotenv_path)\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è Pas de .env (ce n‚Äôest pas bloquant).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51011e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# --- Superuser (pour cr√©er DB / r√¥le)\n",
    "os.environ.setdefault(\"PG_SU_USER\", \"postgres\")\n",
    "os.environ.setdefault(\"PG_SU_PASS\", \"admin\")   # <- mets ici ton vrai mot de passe superuser\n",
    "\n",
    "# --- Cible (base √† cr√©er + user appli)\n",
    "os.environ.setdefault(\"PG_HOST\", \"localhost\")\n",
    "os.environ.setdefault(\"PG_PORT\", \"5432\")\n",
    "os.environ.setdefault(\"PG_DB\",   \"db_accident\")\n",
    "\n",
    "# Option simple : user appli = superuser\n",
    "os.environ.setdefault(\"PG_USER\", os.environ[\"PG_SU_USER\"])\n",
    "os.environ.setdefault(\"PG_PASS\", os.environ[\"PG_SU_PASS\"])\n",
    "\n",
    "print(\"Config OK (mots de passe masqu√©s).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed911a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "def _kw(user, pwd, host, port, dbname):\n",
    "    return dict(\n",
    "        user=user,\n",
    "        password=pwd,\n",
    "        host=host,\n",
    "        port=int(port),\n",
    "        dbname=dbname,\n",
    "        options=\"-c client_encoding=UTF8\",\n",
    "    )\n",
    "\n",
    "def engine_as(user, pwd, host, port, dbname):\n",
    "    import psycopg2\n",
    "    def _creator():\n",
    "        return psycopg2.connect(**_kw(user, pwd, host, port, dbname))\n",
    "    # IMPORTANT : engine sans URL (√©vite tout souci d‚Äôencodage)\n",
    "    return create_engine(\"postgresql+psycopg2://\", creator=_creator, future=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12646158",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import text\n",
    "\n",
    "PG_SU_USER = os.environ[\"PG_SU_USER\"]\n",
    "PG_SU_PASS = os.environ[\"PG_SU_PASS\"]\n",
    "PG_HOST    = os.environ[\"PG_HOST\"]\n",
    "PG_PORT    = os.environ[\"PG_PORT\"]\n",
    "\n",
    "PG_DB      = os.environ[\"PG_DB\"]\n",
    "PG_USER    = os.environ[\"PG_USER\"]\n",
    "PG_PASS    = os.environ[\"PG_PASS\"]\n",
    "\n",
    "created_role = False\n",
    "created_db   = False\n",
    "\n",
    "# Connexion superuser √† la base 'postgres'\n",
    "su_engine = engine_as(PG_SU_USER, PG_SU_PASS, PG_HOST, PG_PORT, \"postgres\")\n",
    "\n",
    "# Pas de transaction pour CREATE ROLE/DB\n",
    "with su_engine.connect().execution_options(isolation_level=\"AUTOCOMMIT\") as conn:\n",
    "    # (1) R√¥le applicatif (si diff√©rent du superuser)\n",
    "    if PG_USER != PG_SU_USER:\n",
    "        role_exists = conn.execute(\n",
    "            text(\"SELECT 1 FROM pg_roles WHERE rolname = :u\"), {\"u\": PG_USER}\n",
    "        ).fetchone()\n",
    "        if not role_exists:\n",
    "            conn.execute(text(f'CREATE ROLE \"{PG_USER}\" LOGIN PASSWORD :p'), {\"p\": PG_PASS})\n",
    "            created_role = True\n",
    "        else:\n",
    "            # on peut s'assurer du mot de passe\n",
    "            conn.execute(text(f'ALTER ROLE \"{PG_USER}\" WITH PASSWORD :p'), {\"p\": PG_PASS})\n",
    "\n",
    "    # (2) Base √† cr√©er si absente\n",
    "    db_exists = conn.execute(\n",
    "        text(\"SELECT 1 FROM pg_database WHERE datname = :d\"), {\"d\": PG_DB}\n",
    "    ).fetchone()\n",
    "    if not db_exists:\n",
    "        owner = PG_USER if PG_USER else PG_SU_USER\n",
    "        conn.execute(text(f'CREATE DATABASE \"{PG_DB}\" OWNER \"{owner}\"'))\n",
    "        created_db = True\n",
    "\n",
    "su_engine.dispose()\n",
    "\n",
    "print(\n",
    "    (\"üÜï Base cr√©√©e. \" if created_db else \"‚úÖ Base d√©j√† existante. \"),\n",
    "    (\"üÜï R√¥le cr√©√©.\" if created_role else \"R√¥le OK.\"),\n",
    "    sep=\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278145c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = engine_as(PG_USER, PG_PASS, PG_HOST, PG_PORT, PG_DB)\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    dbname  = conn.execute(text(\"SELECT current_database()\")).scalar()\n",
    "    version = conn.execute(text(\"SELECT version()\")).scalar()\n",
    "    print(\"DB courante :\", dbname)\n",
    "    print(\"Version     :\", version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13b7b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.begin() as conn:\n",
    "    conn.execute(text('CREATE SCHEMA IF NOT EXISTS db_accident'))\n",
    "    conn.execute(text('CREATE TABLE IF NOT EXISTS db_accident.ping (id serial PRIMARY KEY, ts timestamptz DEFAULT now())'))\n",
    "    conn.execute(text('INSERT INTO db_accident.ping DEFAULT VALUES'))\n",
    "    rows = conn.execute(text('SELECT * FROM db_accident.ping ORDER BY id DESC LIMIT 3')).all()\n",
    "\n",
    "rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e83b87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../notebooks/database_functions-k.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45b4038",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "script_bronze_ddl = \"\"\"\n",
    "CREATE SCHEMA IF NOT EXISTS bronze;\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS bronze.caracteristiques_raw (\n",
    "  identifiant_de_l_accident TEXT,\n",
    "  date_et_heure TEXT,\n",
    "  jour TEXT,\n",
    "  mois TEXT,\n",
    "  annee TEXT,\n",
    "  heure_minute TEXT,\n",
    "  date TEXT,\n",
    "  year_georef TEXT,\n",
    "  lumiere TEXT,\n",
    "  code_postal TEXT,\n",
    "  code_insee TEXT,\n",
    "  departement TEXT,\n",
    "  commune TEXT,\n",
    "  code_commune TEXT,\n",
    "  code_officiel_commune TEXT,\n",
    "  nom_officiel_commune TEXT,\n",
    "  nom_officiel_commune_arrondissement_municipal TEXT,\n",
    "  code_officiel_departement TEXT,\n",
    "  nom_officiel_departement TEXT,\n",
    "  code_officiel_region TEXT,\n",
    "  nom_officiel_region TEXT,\n",
    "  code_officiel_epci TEXT,\n",
    "  nom_officiel_epci TEXT,\n",
    "  localisation TEXT,\n",
    "  intersection TEXT,\n",
    "  conditions_atmospheriques TEXT,\n",
    "  collision TEXT,\n",
    "  adresse TEXT,\n",
    "  gps TEXT,\n",
    "  latitude TEXT,\n",
    "  longitude TEXT,\n",
    "  coordonnees TEXT,\n",
    "  numero TEXT  \n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS bronze.lieux_raw (\n",
    "  identifiant_de_l_accident TEXT,\n",
    "  categorie_route TEXT,\n",
    "  voie TEXT,\n",
    "  v1 TEXT,\n",
    "  v2 TEXT,\n",
    "  circulation TEXT,\n",
    "  nombre_de_voies TEXT,\n",
    "  voie_reservee TEXT,\n",
    "  profil TEXT,\n",
    "  pr TEXT,\n",
    "  pr1 TEXT,\n",
    "  plan TEXT,\n",
    "  largeur_terre_plein_central TEXT,\n",
    "  largeur_de_la_chaussee TEXT,\n",
    "  surface TEXT,\n",
    "  infrastructure TEXT,\n",
    "  situation TEXT,\n",
    "  env1 TEXT\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS bronze.vehicules_raw (\n",
    "  identifiant_de_l_accident TEXT,\n",
    "  identifiant_vehicule TEXT,\n",
    "  sens TEXT,\n",
    "  categorie_vehicule TEXT,\n",
    "  obstacle_fixe_heurte TEXT,\n",
    "  obstacle_mobile_heurte TEXT,\n",
    "  point_de_choc TEXT,\n",
    "  manoeuvre TEXT,\n",
    "  nombre_d_occupants TEXT\n",
    ");\n",
    "\n",
    "\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS bronze.usagers_raw (\n",
    "  identifiant_de_l_accident TEXT,\n",
    "  identifiant_vehicule TEXT,\n",
    "  place TEXT,\n",
    "  categorie_d_usager TEXT,\n",
    "  gravite TEXT,\n",
    "  sexe TEXT,\n",
    "  annee_de_naissance TEXT,\n",
    "  motif_trajet TEXT,\n",
    "  existence_equipement_de_securite TEXT,\n",
    "  utilisation_equipement_de_securite TEXT,\n",
    "  localisation_du_pieton TEXT,\n",
    "  action_pieton TEXT,\n",
    "  pieton_seul_ou_non TEXT\n",
    ");\n",
    "\n",
    "\n",
    "CREATE INDEX IF NOT EXISTS br_car_ident_idx ON bronze.caracteristiques_raw (identifiant_de_l_accident);\n",
    "CREATE INDEX IF NOT EXISTS br_lieux_ident_idx ON bronze.lieux_raw (identifiant_de_l_accident);\n",
    "CREATE INDEX IF NOT EXISTS br_veh_ident_idx ON bronze.vehicules_raw (identifiant_de_l_accident);\n",
    "CREATE INDEX IF NOT EXISTS br_usg_ident_idx ON bronze.usagers_raw (identifiant_de_l_accident);\n",
    "\n",
    "CREATE INDEX IF NOT EXISTS br_car_dep_idx ON bronze.caracteristiques_raw (departement);\n",
    "CREATE INDEX IF NOT EXISTS br_car_date_idx ON bronze.caracteristiques_raw (annee, mois);\n",
    "CREATE INDEX IF NOT EXISTS br_veh_catv_idx ON bronze.vehicules_raw (categorie_vehicule);\n",
    "CREATE INDEX IF NOT EXISTS br_usg_grav_idx ON bronze.usagers_raw (gravite);\n",
    "\"\"\"\n",
    "# ex√©cution du script (on d√©coupe pour ne pas d√©pendre du driver multi-statements)\n",
    "with engine_as(\n",
    "    os.environ[\"PG_USER\"], os.environ[\"PG_PASS\"],\n",
    "    os.environ[\"PG_HOST\"], os.environ[\"PG_PORT\"],\n",
    "    os.environ[\"PG_DB\"]\n",
    ").begin() as conn:\n",
    "    for stmt in script_bronze_ddl.strip().split(\";\\n\"):\n",
    "        s = stmt.strip()\n",
    "        if s:\n",
    "            conn.execute(text(s + \";\"))\n",
    "\n",
    "# def get_engine(db_url: str) -> Engine:\n",
    "#     \"\"\"\n",
    "#     Retourne un SQLAlchemy Engine pour l'URL \n",
    "#     postgresql+psycopg2://user:password@host:port/dbname\n",
    "#     \"\"\"\n",
    "#     return create_engine(db_url, client_encoding=\"utf8\")\n",
    "\n",
    "\n",
    "print(\"‚úÖ DDL bronze appliqu√© (sch√©ma, tables, index).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f7faae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path\n",
    "from sqlalchemy import text\n",
    "\n",
    "CSV = Path.cwd() / \"bronze\" / \"accidents_bronze.csv\"  \n",
    "SCHEMA = \"bronze\"\n",
    "TABLE  = \"caracteristiques_raw\"\n",
    "\n",
    "# 1) lire CSV en texte (s√©parateur ;)\n",
    "df = pd.read_csv(CSV, sep=\";\", encoding=\"utf-8-sig\", dtype=str, low_memory=False)\n",
    "\n",
    "# 2) normaliser noms de colonnes pour coller au DDL\n",
    "def norm(c: str) -> str:\n",
    "    c = str(c).strip().lower()\n",
    "    c = re.sub(r\"\\s+\", \"_\", c)\n",
    "    c = re.sub(r\"[^0-9a-z_]\", \"_\", c)\n",
    "    c = re.sub(r\"_+\", \"_\", c).strip(\"_\")\n",
    "    if c and c[0].isdigit():\n",
    "        c = \"c_\" + c\n",
    "    return c or \"col\"\n",
    "\n",
    "\n",
    "\n",
    "    # if not inplace:\n",
    "    #     df = df.copy()\n",
    "    # def _slug(name: object) -> str:\n",
    "    #     s = \"\" if name is None else str(name)\n",
    "    #     # Normaliser unicode et s√©parer les accents\n",
    "    #     s = unicodedata.normalize(\"NFKD\", s)\n",
    "    #     # Enlever les caract√®res de composition (accents)\n",
    "    #     s = \"\".join(ch for ch in s if not unicodedata.combining(ch))\n",
    "    #     s = s.lower()\n",
    "    #     # Remplacer tout caract√®re non alphanum√©rique par underscore\n",
    "    #     s = re.sub(r\"[^a-z0-9]+\", \"_\", s)\n",
    "    #     # R√©duire underscores multiples et trim\n",
    "    #     s = re.sub(r\"_+\", \"_\", s).strip(\"_\")\n",
    "    #     # Pr√©fixer si commence par chiffre\n",
    "    #     if re.match(r\"^[0-9]\", s):\n",
    "    #         s = \"c_\" + s\n",
    "    #     if s == \"\":\n",
    "    #         s = \"unknown\"\n",
    "    #     return s\n",
    "\n",
    "    # # Appliquer la normalisation\n",
    "    # orig_cols = list(df.columns)\n",
    "    # normalized = [_slug(c) for c in orig_cols]\n",
    "\n",
    "    # # Garantir l'unicit√© des noms\n",
    "    # seen = {}\n",
    "    # unique_cols = []\n",
    "    # for name in normalized:\n",
    "    #     base = name\n",
    "    #     if name not in seen:\n",
    "    #         seen[name] = 1\n",
    "    #         unique_cols.append(name)\n",
    "    #     else:\n",
    "    #         seen[name] += 1\n",
    "    #         new_name = f\"{base}_{seen[name]}\"\n",
    "    #         # garantir que new_name lui-m√™me n'existe pas d√©j√†\n",
    "    #         while new_name in seen:\n",
    "    #             seen[base] += 1\n",
    "    #             new_name = f\"{base}_{seen[base]}\"\n",
    "    #         seen[new_name] = 1\n",
    "    #         unique_cols.append(new_name)\n",
    "\n",
    "    # # Renommer le DataFrame\n",
    "    # mapping = dict(zip(orig_cols, unique_cols))\n",
    "    # df = df.rename(columns=mapping)\n",
    "\n",
    "\n",
    "    # return df\n",
    "\n",
    "df.columns = [norm(c) for c in df.columns]\n",
    "\n",
    "# 3) colonnes attendues par la table (dans l'ordre du DDL, sans ingest_ts qui a un DEFAULT)\n",
    "ddl_cols = [\n",
    "    \"identifiant_de_l_accident\",\n",
    "    \"date_et_heure\",\n",
    "    \"jour\",\n",
    "    \"mois\",\n",
    "    \"annee\",\n",
    "    \"heure_minute\",\n",
    "    \"date\",\n",
    "    \"year_georef\",\n",
    "    \"lumiere\",\n",
    "    \"code_postal\",\n",
    "    \"code_insee\",\n",
    "    \"departement\",\n",
    "    \"commune\",\n",
    "    \"code_commune\",\n",
    "    \"code_officiel_commune\",\n",
    "    \"nom_officiel_commune\",\n",
    "    \"nom_officiel_commune_arrondissement_municipal\",\n",
    "    \"code_officiel_departement\",\n",
    "    \"nom_officiel_departement\",\n",
    "    \"code_officiel_region\",\n",
    "    \"nom_officiel_region\",\n",
    "    \"code_officiel_epci\",\n",
    "    \"nom_officiel_epci\",\n",
    "    \"localisation\",\n",
    "    \"intersection\",\n",
    "    \"conditions_atmospheriques\",\n",
    "    \"collision\",\n",
    "    \"adresse\",\n",
    "    \"gps\",\n",
    "    \"latitude\",\n",
    "    \"longitude\",\n",
    "    \"coordonnees\",\n",
    "    \"numero\"\n",
    "]\n",
    "# ddl_cols = [\n",
    "#   \"identifiant_de_l_accident\",\"date_et_heure\",\"commune\",\"annee\",\"mois\",\"jour\",\"heure_minute\",\"lumiere\",\n",
    "#   \"localisation\",\"intersection\",\"conditions_atmospheriques\",\"collision\",\"departement\",\"code_commune\",\"code_insee\",\n",
    "#   \"adresse\",\"latitude\",\"longitude\",\"code_postal\",\"numero\",\"coordonnees\",\"pr\",\"surface\",\"v1\",\"circulation\",\n",
    "#   \"voie_reservee\",\"env1\",\"voie\",\"largeur_de_la_chaussee\",\"v2\",\"largeur_terre_plein_central\",\"nombre_de_voies\",\n",
    "#   \"categorie_route\",\"pr1\",\"plan\",\"profil\",\"infrastructure\",\"situation\",\"gps\",\"date\",\"year_georef\",\n",
    "#   \"nom_officiel_commune\",\"code_officiel_departement\",\"nom_officiel_departement\",\"code_officiel_epci\",\n",
    "#   \"nom_officiel_epci\",\"code_officiel_region\",\"nom_officiel_region\",\n",
    "#   \"nom_officiel_commune_arrondissement_municipal\",\"code_officiel_commune\",\"source_file\"\n",
    "# ]\n",
    "# table_colonnes = [\n",
    "#     \"identifiant_de_l_accident\",\n",
    "#     \"date_et_heure\",\n",
    "#     \"jour\",\n",
    "#     \"mois\",\n",
    "#     \"annee\",\n",
    "#     \"heure_minute\",\n",
    "#     \"date\",\n",
    "#     \"year_georef\",\n",
    "#     \"lumiere\",\n",
    "#     \"code_postal\",\n",
    "#     \"code_insee\",\n",
    "#     \"departement\",\n",
    "#     \"commune\",\n",
    "#     \"code_commune\",\n",
    "#     \"code_officiel_commune\",\n",
    "#     \"nom_officiel_commune\",\n",
    "#     \"nom_officiel_commune_arrondissement_municipal\",\n",
    "#     \"code_officiel_departement\",\n",
    "#     \"nom_officiel_departement\",\n",
    "#     \"code_officiel_region\",\n",
    "#     \"nom_officiel_region\",\n",
    "#     \"code_officiel_epci\",\n",
    "#     \"nom_officiel_epci\",\n",
    "#     \"localisation\",\n",
    "#     \"intersection\",\n",
    "#     \"conditions_atmospheriques\",\n",
    "#     \"collision\",\n",
    "#     \"adresse\",\n",
    "#     \"gps\",\n",
    "#     \"latitude\",\n",
    "#     \"longitude\",\n",
    "#     \"coordonnees\",\n",
    "#     \"numero\"\n",
    "# ]\n",
    "# 4) ajouter colonnes manquantes, garder seulement celles du DDL, ordonn√©es\n",
    "for col in ddl_cols:\n",
    "    if col not in df.columns:\n",
    "        df[col] = None\n",
    "\n",
    "df[\"source_file\"] = CSV.name  # utile pour tracer l'origine\n",
    "\n",
    "df_to_load = df[ddl_cols]  # exactement l'ordre attendu\n",
    "\n",
    "# 5) append dans la table bronze (simple et s√ªr)\n",
    "engine = engine_as(\n",
    "    os.environ[\"PG_USER\"], os.environ[\"PG_PASS\"],\n",
    "    os.environ[\"PG_HOST\"], os.environ[\"PG_PORT\"],\n",
    "    os.environ[\"PG_DB\"]\n",
    ")\n",
    "\n",
    "# purger la table avant insertion pour √©viter les doublons\n",
    "with engine.begin() as conn:\n",
    "    conn.execute(text(f'TRUNCATE TABLE \"{SCHEMA}\".\"{TABLE}\"'))\n",
    "\n",
    "%time \n",
    "df_to_load.to_sql(\n",
    "    name=TABLE,\n",
    "    schema=SCHEMA,\n",
    "    con=engine,\n",
    "    if_exists=\"append\",     # on recharge √† vide\n",
    "    index=False,\n",
    "    chunksize=10_000,\n",
    "    method=\"multi\",\n",
    ")\n",
    "\n",
    "# 6) v√©rif rapide\n",
    "with engine.connect() as conn:\n",
    "    n = conn.execute(text(f'SELECT COUNT(*) FROM \"{SCHEMA}\".\"{TABLE}\"')).scalar()\n",
    "    print(f\"‚úÖ Chargement termin√© : {n:,} lignes dans {SCHEMA}.{TABLE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28c4945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Test rapide : base courante + sch√©mas existants (PostgreSQL) ---\n",
    "import os\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "PG_USER = os.getenv(\"PG_USER\")\n",
    "PG_PASS = os.getenv(\"PG_PASS\")\n",
    "PG_HOST = os.getenv(\"PG_HOST\", \"127.0.0.1\")\n",
    "PG_PORT = os.getenv(\"PG_PORT\", \"5432\")\n",
    "PG_DB   = os.getenv(\"PG_DB\")\n",
    "\n",
    "engine = create_engine(\n",
    "    f\"postgresql+psycopg2://{PG_USER}:{PG_PASS}@{PG_HOST}:{PG_PORT}/{PG_DB}\",\n",
    "    future=True\n",
    ")\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    db_name = conn.execute(text(\"SELECT current_database()\")).scalar_one()\n",
    "    schemas = conn.execute(text(\"\"\"\n",
    "        SELECT schema_name\n",
    "        FROM information_schema.schemata\n",
    "        ORDER BY schema_name\n",
    "    \"\"\")).scalars().all()\n",
    "\n",
    "    print(f\"Base courante : {db_name}\")\n",
    "    print(\"Sch√©mas disponibles :\")\n",
    "    for s in schemas:\n",
    "        print(f\" - {s}\")\n",
    "\n",
    "    # Optionnel : v√©rifie la pr√©sence d'un sch√©ma cible si SCHEMA est d√©fini\n",
    "    target_schema = os.getenv(\"SCHEMA\")\n",
    "    if target_schema:\n",
    "        print(f\"\\nSch√©ma cible '{target_schema}' pr√©sent ? {'Oui' if target_schema in schemas else 'Non'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8af3917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Fonction pour afficher le sch√©ma d'une table ---\n",
    "def show_table_schema(engine, schema_name: str, table_name: str):\n",
    "    \"\"\"Affiche les colonnes, types et nullabilit√© d'une table donn√©e.\"\"\"\n",
    "    query = text(f\"\"\"\n",
    "        SELECT \n",
    "            column_name, \n",
    "            data_type, \n",
    "            is_nullable, \n",
    "            character_maximum_length\n",
    "        FROM information_schema.columns\n",
    "        WHERE table_schema = :schema\n",
    "          AND table_name = :table\n",
    "        ORDER BY ordinal_position\n",
    "    \"\"\")\n",
    "    with engine.connect() as conn:\n",
    "        rows = conn.execute(query, {\"schema\": schema_name, \"table\": table_name}).fetchall()\n",
    "        if not rows:\n",
    "            print(f\"‚ö†Ô∏è Table '{schema_name}.{table_name}' introuvable.\")\n",
    "            return\n",
    "        print(f\"\\nSch√©ma de la table {schema_name}.{table_name} :\\n\")\n",
    "        for r in rows:\n",
    "            length = f\"({r.character_maximum_length})\" if r.character_maximum_length else \"\"\n",
    "            print(f\"- {r.column_name:<35} {r.data_type:<20} {length}  nullable={r.is_nullable}\")\n",
    "\n",
    "# --- Exemple d'utilisation ---\n",
    "show_table_schema(engine, \"bronze\", \"caracteristiques_raw\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
